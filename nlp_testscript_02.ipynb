{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "2529091b",
   "metadata": {},
   "source": [
    "# Somikorno AI\n",
    "\n",
    "## Quick Test : NLP Problem 1\n",
    "\n",
    "#### Extract Scanned PDF"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7603c55c",
   "metadata": {},
   "source": [
    "#### Goal\n",
    "\n",
    "To extract all Bangla words from a scanned pdf file.\n",
    "\n",
    "\n",
    "To successfully run this notebook you would need to have the followiing packages installed:\n",
    "    \n",
    "1. numpy\n",
    "\n",
    "2. pandas\n",
    "\n",
    "3. opencv\n",
    "\n",
    "4. pytesseract\n",
    "\n",
    "5. pdf2image"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "05b8192e",
   "metadata": {},
   "source": [
    "### Load Required Packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "520c9859",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os\n",
    "import re\n",
    "import json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "afaa1b8e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip3 install opencv\n",
    "# !pip3 install pytersseract\n",
    "# !pip3 install pdf2image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "3477182d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import pytesseract\n",
    "from pdf2image import convert_from_path"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "68978d0b",
   "metadata": {},
   "source": [
    "### Part 1 : Read Data\n",
    "\n",
    "Read the `data_testscript_01.pdf` file from your working directory "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "fc5420e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "pdf_file = 'data_testscript_02.pdf'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "180d333e",
   "metadata": {},
   "source": [
    "Read all pages as a Python list \n",
    "\n",
    "if unfamiliar with the following function, try: help(convert_from_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "5acaff99",
   "metadata": {},
   "outputs": [],
   "source": [
    "pages = convert_from_path(pdf_file, dpi=200, output_folder=None, first_page=None, last_page=None)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3458c481",
   "metadata": {},
   "source": [
    "Main OCR function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "8d35e53d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def main_ocr(current_page, color, black):\n",
    "    \"\"\"\n",
    "    Inputs : \n",
    "    scanned page\n",
    "    color of the page\n",
    "    \n",
    "    Output : \n",
    "    text output from image_to_string method\n",
    "    \n",
    "    \"\"\"\n",
    "    \n",
    "    # step 1 \n",
    "    current_page.save('temp1.jpg', 'JPEG') # save current page as JPEG\n",
    "    \n",
    "    \n",
    "    # step 2\n",
    "    if color == 'g': # color parameter\n",
    "        read_image = cv2.imread(\"temp1.jpg\", cv2.IMREAD_COLOR)     # image read\n",
    "        gray_image = cv2.cvtColor(read_image, cv2.COLOR_BGR2GRAY)  # turn image to gray.\n",
    "        cv2.imwrite(\"temp2.jpg\", gray_image)               # save as gray\n",
    "        \n",
    "    elif color == 'b':\n",
    "        read_image = cv2.imread(\"temp1.jpg\", cv2.IMREAD_COLOR)     # image read\n",
    "        gray_image = cv2.cvtColor(read_image, cv2.COLOR_BGR2GRAY)  # turn image to gray.\n",
    "        (thresh, BnW_image) = cv2.threshold(gray_image, black, 255, cv2.THRESH_BINARY) # this controls color temp\n",
    "        cv2.imwrite(\"temp2.jpg\", BnW_image)                # save as black and white\n",
    "\n",
    "    \n",
    "    # step 3\n",
    "    text = pytesseract.image_to_string('temp2.jpg', lang='ben') # scan page\n",
    "\n",
    "    return text"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9acff4e5",
   "metadata": {},
   "source": [
    "Total number of pmages read"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "fc31077b",
   "metadata": {},
   "outputs": [],
   "source": [
    "total_page = len(pages)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b0cfaa7f",
   "metadata": {},
   "source": [
    "Main Data Processing Section"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "7abbfcd2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Scaning page: 1\n",
      "Scaning page: 2\n",
      "Scaning page: 3\n",
      "Scaning page: 4\n",
      "Scaning page: 5\n",
      "Scaning page: 6\n",
      "Scaning page: 7\n",
      "Scaning page: 8\n",
      "Scaning page: 9\n",
      "Scaning page: 10\n",
      "Scaning page: 11\n",
      "Scaning page: 12\n",
      "Scaning page: 13\n",
      "Scaning page: 14\n",
      "Scaning page: 15\n",
      "Scaning page: 16\n",
      "Scaning page: 17\n",
      "Scaning page: 18\n",
      "Scaning page: 19\n",
      "Scaning page: 20\n",
      "Scaning page: 21\n",
      "Scaning page: 22\n",
      "Scaning page: 23\n",
      "Scaning page: 24\n",
      "Scaning page: 25\n"
     ]
    }
   ],
   "source": [
    "# test complete? if yes then continue\n",
    "\n",
    "start_page = 0          # first page\n",
    "end_page = total_page   # last page\n",
    "\n",
    "dataList = []   # storage of each page as a list\n",
    "\n",
    "for i in range(start_page, end_page):\n",
    "    print(\"Scaning page:\", i+1)\n",
    "    dataList.append( main_ocr(pages[i], 'g', 160) )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b76ead80",
   "metadata": {},
   "source": [
    "### Paer 2: Clean Data \n",
    "\n",
    "#### Split each page using `pattern='\\n'`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "282b8385",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = dataList.copy()\n",
    "\n",
    "for i, _data in enumerate(dataList):    # i index & data\n",
    "    data[i] = ?????                     # split where \"\\n\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2333c7f7",
   "metadata": {},
   "source": [
    "The pages of the book now appears as a list of lists.\n",
    "\n",
    "Pages are all full of punctuation marks and special characters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "0b4b389d",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Have a look at the data\n",
    "# data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9edce25b",
   "metadata": {},
   "source": [
    "Clean text\n",
    "\n",
    "Search for patterns in the text. When found, just remove."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "3f2f81ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i, _data in enumerate(data):\n",
    "    temp = [] # temp store\n",
    "    for line in _data:\n",
    "        temp.extend(line.split(\"|\")) # where string will be split\n",
    "    data[i] = temp\n",
    "\n",
    "for i, _data in enumerate(data):\n",
    "    temp = []\n",
    "    for line in _data:\n",
    "        temp.extend(line.split(\" \")) # where string will be split\n",
    "    data[i] = temp\n",
    "    \n",
    "for i, _data in enumerate(data):\n",
    "    temp = []\n",
    "    for line in _data:\n",
    "        temp.extend(line.split(\"-\")) # where string will be split\n",
    "    data[i] = temp\n",
    "\n",
    "for i, _data in enumerate(data):\n",
    "    temp = []\n",
    "    for line in _data:\n",
    "        temp.extend(line.split(\",\")) # where string will be split\n",
    "    data[i] = temp\n",
    "    \n",
    "for i, _data in enumerate(data):\n",
    "    temp = []\n",
    "    for line in _data:\n",
    "        temp.extend(line.split(\"?\")) # where string will be split\n",
    "    data[i] = temp\n",
    "    \n",
    "for i, _data in enumerate(data):\n",
    "    temp = []\n",
    "    for line in _data:\n",
    "        temp.extend(line.split(\"!\")) # where string will be split\n",
    "    data[i] = temp"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f3d25b1b",
   "metadata": {},
   "source": [
    "Further clean text\n",
    "\n",
    "Remove special characters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "ec58ddc3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# remove or ignore all chars present in the 'ignore_list'\n",
    "ignore_list = \"!#$%&'()\\n”*+”“,-.৷'/:;<=>?[]@\\^_|`{|}~।ঃ\"+'\"' \n",
    "\n",
    "for i, _data in enumerate(data):\n",
    "    temp = []\n",
    "    \n",
    "    for word in _data:\n",
    "#         print(word)\n",
    "\n",
    "        for char in word:\n",
    "            if char in ignore_list:\n",
    "                word = word.replace(char, '')\n",
    "            if char.isdigit():\n",
    "                word = word.replace(char, '') \n",
    "        if len(word) != 0: \n",
    "            temp.append(word)    \n",
    "    data[i] = temp"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "216bea84",
   "metadata": {},
   "source": [
    "Create a dictionary : each page numbger is the key, the list of words in each page is the value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "082ab9f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "dictionary = {}\n",
    "\n",
    "for i ,_data in enumerate(data):\n",
    "    dictionary[i] = _data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "83b43bed",
   "metadata": {},
   "source": [
    "#### Print the dictionary. How many mis-spelled words can you recognize? \n",
    "\n",
    "What are the reasons can you think behind these bad recognition? \n",
    "Hint: Look at the pdf file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "4647a352",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# print(dictionary)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "754bde97",
   "metadata": {},
   "source": [
    "#### Save cleaned data to a json file. \n",
    "\n",
    "You need add a few keywords to the following lines of codes so that you can open Bangla text in the out file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c59f75de",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"out_testscript_02.json\", \"w\", ????) as outfile:\n",
    "    json.dump(dictionary, outfile, ??????)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "befff79e",
   "metadata": {},
   "source": [
    "#### Collect the words from all pages in a single list\n",
    "\n",
    "Hint: you will need a do loop and a new list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe87d0d8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "a7912698",
   "metadata": {},
   "source": [
    "#### Count the number of each word\n",
    "Hint : you can do this in 2 ways: 1) use `numpy unique method` applied on the created list above or 2) create a dataframe with one column which will have each word as a row. Then you can use pandas `value_count` method."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "85c0de6e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2623\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>unique_values</th>\n",
       "      <th>counts</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>না</td>\n",
       "      <td>289</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>আমি</td>\n",
       "      <td>189</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>আমার</td>\n",
       "      <td>134</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>করে</td>\n",
       "      <td>121</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>তার</td>\n",
       "      <td>95</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3385</th>\n",
       "      <td>গ্</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3386</th>\n",
       "      <td>অরুচির</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3387</th>\n",
       "      <td>তেইশ</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3388</th>\n",
       "      <td>পুরুষরা</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3389</th>\n",
       "      <td>কত</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3390 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     unique_values  counts\n",
       "0               না     289\n",
       "1              আমি     189\n",
       "2             আমার     134\n",
       "3              করে     121\n",
       "4              তার      95\n",
       "...            ...     ...\n",
       "3385            গ্       1\n",
       "3386        অরুচির       1\n",
       "3387          তেইশ       1\n",
       "3388       পুরুষরা       1\n",
       "3389            কত       1\n",
       "\n",
       "[3390 rows x 2 columns]"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "f21c1525",
   "metadata": {},
   "source": [
    "#### Do you see the potential challenges in extarcting Bangla text using pytesseract?\n",
    "\n",
    "How else would you proceed? in terms of data, in terms of algorithm."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
