{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b33cdfcd",
   "metadata": {},
   "source": [
    "# Quick Test : NLP Problem\n",
    "\n",
    "#### Extract Scanned PDF"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6dd0c4e8",
   "metadata": {},
   "source": [
    "### Goal \n",
    "\n",
    "To extract all meaningful english words from a scanned pdf file. This is a classic NLP problem.\n",
    "\n",
    "\n",
    "### Some Key Points to Keep in  Mind\n",
    "\n",
    "1. One of the most critical programming skill that is need in NLP is to know how to use regular expression. Use regular expression quick help : https://www.w3schools.com/python/python_regex.asp\n",
    "\n",
    "2. Regular expression is needed for cleaning textual data\n",
    "\n",
    "3. You may or may not use `stemmer` to extract meaningful words/strings"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "94570650",
   "metadata": {},
   "source": [
    "## Load Required Packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "id": "215315d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# pip3 install pypdf2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b61d8455",
   "metadata": {},
   "source": [
    "-------------------------------------------------------------------------------------------------"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bc92e9ee",
   "metadata": {},
   "source": [
    "## Part 1 :  Read Data\n",
    "\n",
    "####  Read the pdf file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "id": "d211c49d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import PyPDF2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "id": "fb0353f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "reader = PyPDF2.PdfFileReader(open('example.pdf','rb'))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4592f0f9",
   "metadata": {},
   "source": [
    "#### Find the number of pages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "id": "15a50ffe",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4\n"
     ]
    }
   ],
   "source": [
    "number_of_pages = reader.getNumPages()\n",
    "print(number_of_pages)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c39bc5c9",
   "metadata": {},
   "source": [
    "#### Get the first page : indexed by 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "id": "1e554cd5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'/Type': '/Page', '/Parent': IndirectObject(3, 0, 140113047650800), '/Resources': IndirectObject(6, 0, 140113047650800), '/Contents': IndirectObject(4, 0, 140113047650800), '/MediaBox': [0, 0, 595, 842], '/Rotate': 0}\n"
     ]
    }
   ],
   "source": [
    "page = reader.pages[0]\n",
    "print(page)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3bc73e08",
   "metadata": {},
   "source": [
    "#### Get text from the first page "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "id": "b46c34b5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 1 \n",
      " \n",
      "The Impact of Sample Bias on Consumer Credit \n",
      "Scoring Performance and Profitability \n",
      " \n",
      " \n",
      " \n",
      "Abstract \n",
      " \n",
      "This article seeks to gain insight into the influence of sample bias in a consumer credit \n",
      "scoring model. Considering the vital implications on revenues and costs concerned with the \n",
      "issuing and repayment of commercial credit, predictive performance of the model is crucial, \n",
      "and sample bias has been suggested to pose a sizeable threat to profitability due to its \n",
      "implications on either population drainage or biased estimates.  Whereas in previous \n",
      "research, different techniques of reducing sample bias have been proposed and deployed, \n",
      "the debate around the impact of sample bias itself has predominantly been held on a \n",
      "theoretical level. The dataset that was used in this study, however, provides the opportunity \n",
      "to investigate the issue in an empirical setting.  Based on the data of a mail-order company \n",
      "offering short term consumer credit to their consumers, we show that (i) given a certain \n",
      "sample size, sample bias has a significant effect on consumer credit-scoring performance and \n",
      "profitability, (ii)  its effect is composed of the inclusion of rejected orders in the scoring \n",
      "model, and the inclusion of these orders into the variable-selection process, (iii) the impact of \n",
      "the effect of sample bias on consumer credit scoring performance and profitability is limited \n",
      "and (iv) in consumer credit scoring, by merely increasing the sample size of the biased \n",
      "sample, the impact of sample bias can likely be reduced. Hence, we conclude that the \n",
      "possible impact of any reduction of sample bias is modest in a consumer credit scoring \n",
      "model, and that attention might optimally be focused on other factors leading to improved \n",
      "consumer credit scoring. \n",
      " \n",
      "Keywords: Consumer Credit Scoring; Sample Bias; Reject Inference.  \n",
      " \n",
      " \n"
     ]
    }
   ],
   "source": [
    "text = page.extract_text()\n",
    "print(text)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c9f14d76",
   "metadata": {},
   "source": [
    "-------------------------------------------------------------------------------------------------"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d6b04880",
   "metadata": {},
   "source": [
    "Everything that has been written below has been done for Page 1 only "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "687c57a5",
   "metadata": {},
   "source": [
    "-------------------------------------------------------------------------------------------------"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1e4b33e3",
   "metadata": {},
   "source": [
    "## Part 2: Clean Data\n",
    "\n",
    "#### Step 1: Split the text by white-space"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "id": "58c45b39",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['', '1', '\\n', '\\nThe', 'Impact', 'of', 'Sample', 'Bias', 'on', 'Consumer', 'Credit', '\\nScoring', 'Performance', 'and', 'Profitability', '\\n', '\\n', '\\n', '\\nAbstract', '\\n', '\\nThis', 'article', 'seeks', 'to', 'gain', 'insight', 'into', 'the', 'influence', 'of', 'sample', 'bias', 'in', 'a', 'consumer', 'credit', '\\nscoring', 'model.', 'Considering', 'the', 'vital', 'implications', 'on', 'revenues', 'and', 'costs', 'concerned', 'with', 'the', '\\nissuing', 'and', 'repayment', 'of', 'commercial', 'credit,', 'predictive', 'performance', 'of', 'the', 'model', 'is', 'crucial,', '\\nand', 'sample', 'bias', 'has', 'been', 'suggested', 'to', 'pose', 'a', 'sizeable', 'threat', 'to', 'profitability', 'due', 'to', 'its', '\\nimplications', 'on', 'either', 'population', 'drainage', 'or', 'biased', 'estimates.', '', 'Whereas', 'in', 'previous', '\\nresearch,', 'different', 'techniques', 'of', 'reducing', 'sample', 'bias', 'have', 'been', 'proposed', 'and', 'deployed,', '\\nthe', 'debate', 'around', 'the', 'impact', 'of', 'sample', 'bias', 'itself', 'has', 'predominantly', 'been', 'held', 'on', 'a', '\\ntheoretical', 'level.', 'The', 'dataset', 'that', 'was', 'used', 'in', 'this', 'study,', 'however,', 'provides', 'the', 'opportunity', '\\nto', 'investigate', 'the', 'issue', 'in', 'an', 'empirical', 'setting.', '', 'Based', 'on', 'the', 'data', 'of', 'a', 'mail-order', 'company', '\\noffering', 'short', 'term', 'consumer', 'credit', 'to', 'their', 'consumers,', 'we', 'show', 'that', '(i)', 'given', 'a', 'certain', '\\nsample', 'size,', 'sample', 'bias', 'has', 'a', 'significant', 'effect', 'on', 'consumer', 'credit-scoring', 'performance', 'and', '\\nprofitability,', '(ii)', '', 'its', 'effect', 'is', 'composed', 'of', 'the', 'inclusion', 'of', 'rejected', 'orders', 'in', 'the', 'scoring', '\\nmodel,', 'and', 'the', 'inclusion', 'of', 'these', 'orders', 'into', 'the', 'variable-selection', 'process,', '(iii)', 'the', 'impact', 'of', '\\nthe', 'effect', 'of', 'sample', 'bias', 'on', 'consumer', 'credit', 'scoring', 'performance', 'and', 'profitability', 'is', 'limited', '\\nand', '(iv)', 'in', 'consumer', 'credit', 'scoring,', 'by', 'merely', 'increasing', 'the', 'sample', 'size', 'of', 'the', 'biased', '\\nsample,', 'the', 'impact', 'of', 'sample', 'bias', 'can', 'likely', 'be', 'reduced.', 'Hence,', 'we', 'conclude', 'that', 'the', '\\npossible', 'impact', 'of', 'any', 'reduction', 'of', 'sample', 'bias', 'is', 'modest', 'in', 'a', 'consumer', 'credit', 'scoring', '\\nmodel,', 'and', 'that', 'attention', 'might', 'optimally', 'be', 'focused', 'on', 'other', 'factors', 'leading', 'to', 'improved', '\\nconsumer', 'credit', 'scoring.', '\\n', '\\nKeywords:', 'Consumer', 'Credit', 'Scoring;', 'Sample', 'Bias;', 'Reject', 'Inference.', '', '\\n', '\\n', '']\n"
     ]
    }
   ],
   "source": [
    "_text1 = text.split(\" \")\n",
    "print( _text1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d2326888",
   "metadata": {},
   "source": [
    "#### Step 2 : Remove newline brake  and white space"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0dcb0c0d",
   "metadata": {},
   "source": [
    "Check & Learn : Use of replace() method"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "id": "1cde8968",
   "metadata": {},
   "outputs": [],
   "source": [
    "#'\\nBangladesh'.replace('\\n','')\n",
    "#'\\nBangladesh\\n'.replace('\\n','')\n",
    "#'\\n\\nBangladesh\\n'.replace('\\n','')\n",
    "#'\\n\\nBangladesh\\\\n'.replace('\\n','')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ee5422fb",
   "metadata": {},
   "source": [
    "Check and Learn : Use of strip() method"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "id": "0fbf7336",
   "metadata": {},
   "outputs": [],
   "source": [
    "#' Bangaldesh Data Science '.strip()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c724d201",
   "metadata": {},
   "source": [
    "Check & Learn : Combine the two methods"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "id": "aacafad2",
   "metadata": {},
   "outputs": [],
   "source": [
    "#' \\nBangaldesh Data Science\\n '.replace('\\n','').strip()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b06f5734",
   "metadata": {},
   "source": [
    "Step 2a : Apply your newly acquired knowledge to the original problem  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "id": "36fd8d85",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['', '1', '', 'The', 'Impact', 'of', 'Sample', 'Bias', 'on', 'Consumer', 'Credit', 'Scoring', 'Performance', 'and', 'Profitability', '', '', '', 'Abstract', '', 'This', 'article', 'seeks', 'to', 'gain', 'insight', 'into', 'the', 'influence', 'of', 'sample', 'bias', 'in', 'a', 'consumer', 'credit', 'scoring', 'model.', 'Considering', 'the', 'vital', 'implications', 'on', 'revenues', 'and', 'costs', 'concerned', 'with', 'the', 'issuing', 'and', 'repayment', 'of', 'commercial', 'credit,', 'predictive', 'performance', 'of', 'the', 'model', 'is', 'crucial,', 'and', 'sample', 'bias', 'has', 'been', 'suggested', 'to', 'pose', 'a', 'sizeable', 'threat', 'to', 'profitability', 'due', 'to', 'its', 'implications', 'on', 'either', 'population', 'drainage', 'or', 'biased', 'estimates.', '', 'Whereas', 'in', 'previous', 'research,', 'different', 'techniques', 'of', 'reducing', 'sample', 'bias', 'have', 'been', 'proposed', 'and', 'deployed,', 'the', 'debate', 'around', 'the', 'impact', 'of', 'sample', 'bias', 'itself', 'has', 'predominantly', 'been', 'held', 'on', 'a', 'theoretical', 'level.', 'The', 'dataset', 'that', 'was', 'used', 'in', 'this', 'study,', 'however,', 'provides', 'the', 'opportunity', 'to', 'investigate', 'the', 'issue', 'in', 'an', 'empirical', 'setting.', '', 'Based', 'on', 'the', 'data', 'of', 'a', 'mail-order', 'company', 'offering', 'short', 'term', 'consumer', 'credit', 'to', 'their', 'consumers,', 'we', 'show', 'that', '(i)', 'given', 'a', 'certain', 'sample', 'size,', 'sample', 'bias', 'has', 'a', 'significant', 'effect', 'on', 'consumer', 'credit-scoring', 'performance', 'and', 'profitability,', '(ii)', '', 'its', 'effect', 'is', 'composed', 'of', 'the', 'inclusion', 'of', 'rejected', 'orders', 'in', 'the', 'scoring', 'model,', 'and', 'the', 'inclusion', 'of', 'these', 'orders', 'into', 'the', 'variable-selection', 'process,', '(iii)', 'the', 'impact', 'of', 'the', 'effect', 'of', 'sample', 'bias', 'on', 'consumer', 'credit', 'scoring', 'performance', 'and', 'profitability', 'is', 'limited', 'and', '(iv)', 'in', 'consumer', 'credit', 'scoring,', 'by', 'merely', 'increasing', 'the', 'sample', 'size', 'of', 'the', 'biased', 'sample,', 'the', 'impact', 'of', 'sample', 'bias', 'can', 'likely', 'be', 'reduced.', 'Hence,', 'we', 'conclude', 'that', 'the', 'possible', 'impact', 'of', 'any', 'reduction', 'of', 'sample', 'bias', 'is', 'modest', 'in', 'a', 'consumer', 'credit', 'scoring', 'model,', 'and', 'that', 'attention', 'might', 'optimally', 'be', 'focused', 'on', 'other', 'factors', 'leading', 'to', 'improved', 'consumer', 'credit', 'scoring.', '', 'Keywords:', 'Consumer', 'Credit', 'Scoring;', 'Sample', 'Bias;', 'Reject', 'Inference.', '', '', '', '']\n"
     ]
    }
   ],
   "source": [
    "_text2a = []\n",
    "for text in _text1:\n",
    "    _text2a.append(str(text).replace('\\n','').strip())\n",
    "print(_text2a)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "51ddf9ed",
   "metadata": {},
   "source": [
    "Step 2b : Remove strings with length =  0 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "id": "e73ca756",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['1', 'The', 'Impact', 'of', 'Sample', 'Bias', 'on', 'Consumer', 'Credit', 'Scoring', 'Performance', 'and', 'Profitability', 'Abstract', 'This', 'article', 'seeks', 'to', 'gain', 'insight', 'into', 'the', 'influence', 'of', 'sample', 'bias', 'in', 'a', 'consumer', 'credit', 'scoring', 'model.', 'Considering', 'the', 'vital', 'implications', 'on', 'revenues', 'and', 'costs', 'concerned', 'with', 'the', 'issuing', 'and', 'repayment', 'of', 'commercial', 'credit,', 'predictive', 'performance', 'of', 'the', 'model', 'is', 'crucial,', 'and', 'sample', 'bias', 'has', 'been', 'suggested', 'to', 'pose', 'a', 'sizeable', 'threat', 'to', 'profitability', 'due', 'to', 'its', 'implications', 'on', 'either', 'population', 'drainage', 'or', 'biased', 'estimates.', 'Whereas', 'in', 'previous', 'research,', 'different', 'techniques', 'of', 'reducing', 'sample', 'bias', 'have', 'been', 'proposed', 'and', 'deployed,', 'the', 'debate', 'around', 'the', 'impact', 'of', 'sample', 'bias', 'itself', 'has', 'predominantly', 'been', 'held', 'on', 'a', 'theoretical', 'level.', 'The', 'dataset', 'that', 'was', 'used', 'in', 'this', 'study,', 'however,', 'provides', 'the', 'opportunity', 'to', 'investigate', 'the', 'issue', 'in', 'an', 'empirical', 'setting.', 'Based', 'on', 'the', 'data', 'of', 'a', 'mail-order', 'company', 'offering', 'short', 'term', 'consumer', 'credit', 'to', 'their', 'consumers,', 'we', 'show', 'that', '(i)', 'given', 'a', 'certain', 'sample', 'size,', 'sample', 'bias', 'has', 'a', 'significant', 'effect', 'on', 'consumer', 'credit-scoring', 'performance', 'and', 'profitability,', '(ii)', 'its', 'effect', 'is', 'composed', 'of', 'the', 'inclusion', 'of', 'rejected', 'orders', 'in', 'the', 'scoring', 'model,', 'and', 'the', 'inclusion', 'of', 'these', 'orders', 'into', 'the', 'variable-selection', 'process,', '(iii)', 'the', 'impact', 'of', 'the', 'effect', 'of', 'sample', 'bias', 'on', 'consumer', 'credit', 'scoring', 'performance', 'and', 'profitability', 'is', 'limited', 'and', '(iv)', 'in', 'consumer', 'credit', 'scoring,', 'by', 'merely', 'increasing', 'the', 'sample', 'size', 'of', 'the', 'biased', 'sample,', 'the', 'impact', 'of', 'sample', 'bias', 'can', 'likely', 'be', 'reduced.', 'Hence,', 'we', 'conclude', 'that', 'the', 'possible', 'impact', 'of', 'any', 'reduction', 'of', 'sample', 'bias', 'is', 'modest', 'in', 'a', 'consumer', 'credit', 'scoring', 'model,', 'and', 'that', 'attention', 'might', 'optimally', 'be', 'focused', 'on', 'other', 'factors', 'leading', 'to', 'improved', 'consumer', 'credit', 'scoring.', 'Keywords:', 'Consumer', 'Credit', 'Scoring;', 'Sample', 'Bias;', 'Reject', 'Inference.']\n"
     ]
    }
   ],
   "source": [
    "_text2b = []\n",
    "\n",
    "for text in _text2a:\n",
    "    if len(text) != 0:\n",
    "        _text2b.append(text)\n",
    "print(_text2b)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0b185982",
   "metadata": {},
   "source": [
    "#### Step 3 : Remove special characters, such as,  full  stop, comma, color,  semi-colon, etc. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "59027971",
   "metadata": {},
   "source": [
    "We need a special package called `re`, aka, `regular expression`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "id": "ef11c0aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8fe66d31",
   "metadata": {},
   "source": [
    "Check and Learn : use 'sub' function to remove special characters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "id": "c86718a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "#re.sub('[:;.\\[\\]]','','.[Bias Term];')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "id": "d6b7b19d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['1', 'The', 'Impact', 'of', 'Sample', 'Bias', 'on', 'Consumer', 'Credit', 'Scoring', 'Performance', 'and', 'Profitability', 'Abstract', 'This', 'article', 'seeks', 'to', 'gain', 'insight', 'into', 'the', 'influence', 'of', 'sample', 'bias', 'in', 'a', 'consumer', 'credit', 'scoring', 'model', 'Considering', 'the', 'vital', 'implications', 'on', 'revenues', 'and', 'costs', 'concerned', 'with', 'the', 'issuing', 'and', 'repayment', 'of', 'commercial', 'credit', 'predictive', 'performance', 'of', 'the', 'model', 'is', 'crucial', 'and', 'sample', 'bias', 'has', 'been', 'suggested', 'to', 'pose', 'a', 'sizeable', 'threat', 'to', 'profitability', 'due', 'to', 'its', 'implications', 'on', 'either', 'population', 'drainage', 'or', 'biased', 'estimates', 'Whereas', 'in', 'previous', 'research', 'different', 'techniques', 'of', 'reducing', 'sample', 'bias', 'have', 'been', 'proposed', 'and', 'deployed', 'the', 'debate', 'around', 'the', 'impact', 'of', 'sample', 'bias', 'itself', 'has', 'predominantly', 'been', 'held', 'on', 'a', 'theoretical', 'level', 'The', 'dataset', 'that', 'was', 'used', 'in', 'this', 'study', 'however', 'provides', 'the', 'opportunity', 'to', 'investigate', 'the', 'issue', 'in', 'an', 'empirical', 'setting', 'Based', 'on', 'the', 'data', 'of', 'a', 'mail-order', 'company', 'offering', 'short', 'term', 'consumer', 'credit', 'to', 'their', 'consumers', 'we', 'show', 'that', '(i)', 'given', 'a', 'certain', 'sample', 'size', 'sample', 'bias', 'has', 'a', 'significant', 'effect', 'on', 'consumer', 'credit-scoring', 'performance', 'and', 'profitability', '(ii)', 'its', 'effect', 'is', 'composed', 'of', 'the', 'inclusion', 'of', 'rejected', 'orders', 'in', 'the', 'scoring', 'model', 'and', 'the', 'inclusion', 'of', 'these', 'orders', 'into', 'the', 'variable-selection', 'process', '(iii)', 'the', 'impact', 'of', 'the', 'effect', 'of', 'sample', 'bias', 'on', 'consumer', 'credit', 'scoring', 'performance', 'and', 'profitability', 'is', 'limited', 'and', '(iv)', 'in', 'consumer', 'credit', 'scoring', 'by', 'merely', 'increasing', 'the', 'sample', 'size', 'of', 'the', 'biased', 'sample', 'the', 'impact', 'of', 'sample', 'bias', 'can', 'likely', 'be', 'reduced', 'Hence', 'we', 'conclude', 'that', 'the', 'possible', 'impact', 'of', 'any', 'reduction', 'of', 'sample', 'bias', 'is', 'modest', 'in', 'a', 'consumer', 'credit', 'scoring', 'model', 'and', 'that', 'attention', 'might', 'optimally', 'be', 'focused', 'on', 'other', 'factors', 'leading', 'to', 'improved', 'consumer', 'credit', 'scoring', 'Keywords', 'Consumer', 'Credit', 'Scoring', 'Sample', 'Bias', 'Reject', 'Inference']\n",
      "\n",
      "number of total strings : 282\n"
     ]
    }
   ],
   "source": [
    "_text3 = []\n",
    "\n",
    "for text in _text2b:\n",
    "    _text3.append(re.sub('[:,;.\\[\\]]', '', text))\n",
    "\n",
    "print(_text3)\n",
    "print('')\n",
    "print( 'number of total strings :', len(_text3) )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "903e8ff8",
   "metadata": {},
   "source": [
    "#### Step 4 : Remove un-wanted  strings, such as, (i), (ii), (iii), ... etc."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "id": "2f80b5ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "# s = '(i) this is item number one, (ii) this is item number two'\n",
    "# re.sub('\\([a-z]+\\)','',s)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "id": "0b5965e3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['1', 'The', 'Impact', 'of', 'Sample', 'Bias', 'on', 'Consumer', 'Credit', 'Scoring', 'Performance', 'and', 'Profitability', 'Abstract', 'This', 'article', 'seeks', 'to', 'gain', 'insight', 'into', 'the', 'influence', 'of', 'sample', 'bias', 'in', 'a', 'consumer', 'credit', 'scoring', 'model', 'Considering', 'the', 'vital', 'implications', 'on', 'revenues', 'and', 'costs', 'concerned', 'with', 'the', 'issuing', 'and', 'repayment', 'of', 'commercial', 'credit', 'predictive', 'performance', 'of', 'the', 'model', 'is', 'crucial', 'and', 'sample', 'bias', 'has', 'been', 'suggested', 'to', 'pose', 'a', 'sizeable', 'threat', 'to', 'profitability', 'due', 'to', 'its', 'implications', 'on', 'either', 'population', 'drainage', 'or', 'biased', 'estimates', 'Whereas', 'in', 'previous', 'research', 'different', 'techniques', 'of', 'reducing', 'sample', 'bias', 'have', 'been', 'proposed', 'and', 'deployed', 'the', 'debate', 'around', 'the', 'impact', 'of', 'sample', 'bias', 'itself', 'has', 'predominantly', 'been', 'held', 'on', 'a', 'theoretical', 'level', 'The', 'dataset', 'that', 'was', 'used', 'in', 'this', 'study', 'however', 'provides', 'the', 'opportunity', 'to', 'investigate', 'the', 'issue', 'in', 'an', 'empirical', 'setting', 'Based', 'on', 'the', 'data', 'of', 'a', 'mail-order', 'company', 'offering', 'short', 'term', 'consumer', 'credit', 'to', 'their', 'consumers', 'we', 'show', 'that', '', 'given', 'a', 'certain', 'sample', 'size', 'sample', 'bias', 'has', 'a', 'significant', 'effect', 'on', 'consumer', 'credit-scoring', 'performance', 'and', 'profitability', '', 'its', 'effect', 'is', 'composed', 'of', 'the', 'inclusion', 'of', 'rejected', 'orders', 'in', 'the', 'scoring', 'model', 'and', 'the', 'inclusion', 'of', 'these', 'orders', 'into', 'the', 'variable-selection', 'process', '', 'the', 'impact', 'of', 'the', 'effect', 'of', 'sample', 'bias', 'on', 'consumer', 'credit', 'scoring', 'performance', 'and', 'profitability', 'is', 'limited', 'and', '', 'in', 'consumer', 'credit', 'scoring', 'by', 'merely', 'increasing', 'the', 'sample', 'size', 'of', 'the', 'biased', 'sample', 'the', 'impact', 'of', 'sample', 'bias', 'can', 'likely', 'be', 'reduced', 'Hence', 'we', 'conclude', 'that', 'the', 'possible', 'impact', 'of', 'any', 'reduction', 'of', 'sample', 'bias', 'is', 'modest', 'in', 'a', 'consumer', 'credit', 'scoring', 'model', 'and', 'that', 'attention', 'might', 'optimally', 'be', 'focused', 'on', 'other', 'factors', 'leading', 'to', 'improved', 'consumer', 'credit', 'scoring', 'Keywords', 'Consumer', 'Credit', 'Scoring', 'Sample', 'Bias', 'Reject', 'Inference']\n",
      "\n",
      "number of total strings : 282\n"
     ]
    }
   ],
   "source": [
    "_text4a = []\n",
    "\n",
    "for text in _text3:\n",
    "    _text4a.append(re.sub('\\([a-z]+\\)','',text))\n",
    "\n",
    "print(_text4a)\n",
    "print('')\n",
    "print( 'number of total strings :', len(_text4a) )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7b91f7db",
   "metadata": {},
   "source": [
    "Remove strings with length 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "id": "bf5ab6d6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['1', 'The', 'Impact', 'of', 'Sample', 'Bias', 'on', 'Consumer', 'Credit', 'Scoring', 'Performance', 'and', 'Profitability', 'Abstract', 'This', 'article', 'seeks', 'to', 'gain', 'insight', 'into', 'the', 'influence', 'of', 'sample', 'bias', 'in', 'a', 'consumer', 'credit', 'scoring', 'model', 'Considering', 'the', 'vital', 'implications', 'on', 'revenues', 'and', 'costs', 'concerned', 'with', 'the', 'issuing', 'and', 'repayment', 'of', 'commercial', 'credit', 'predictive', 'performance', 'of', 'the', 'model', 'is', 'crucial', 'and', 'sample', 'bias', 'has', 'been', 'suggested', 'to', 'pose', 'a', 'sizeable', 'threat', 'to', 'profitability', 'due', 'to', 'its', 'implications', 'on', 'either', 'population', 'drainage', 'or', 'biased', 'estimates', 'Whereas', 'in', 'previous', 'research', 'different', 'techniques', 'of', 'reducing', 'sample', 'bias', 'have', 'been', 'proposed', 'and', 'deployed', 'the', 'debate', 'around', 'the', 'impact', 'of', 'sample', 'bias', 'itself', 'has', 'predominantly', 'been', 'held', 'on', 'a', 'theoretical', 'level', 'The', 'dataset', 'that', 'was', 'used', 'in', 'this', 'study', 'however', 'provides', 'the', 'opportunity', 'to', 'investigate', 'the', 'issue', 'in', 'an', 'empirical', 'setting', 'Based', 'on', 'the', 'data', 'of', 'a', 'mail-order', 'company', 'offering', 'short', 'term', 'consumer', 'credit', 'to', 'their', 'consumers', 'we', 'show', 'that', 'given', 'a', 'certain', 'sample', 'size', 'sample', 'bias', 'has', 'a', 'significant', 'effect', 'on', 'consumer', 'credit-scoring', 'performance', 'and', 'profitability', 'its', 'effect', 'is', 'composed', 'of', 'the', 'inclusion', 'of', 'rejected', 'orders', 'in', 'the', 'scoring', 'model', 'and', 'the', 'inclusion', 'of', 'these', 'orders', 'into', 'the', 'variable-selection', 'process', 'the', 'impact', 'of', 'the', 'effect', 'of', 'sample', 'bias', 'on', 'consumer', 'credit', 'scoring', 'performance', 'and', 'profitability', 'is', 'limited', 'and', 'in', 'consumer', 'credit', 'scoring', 'by', 'merely', 'increasing', 'the', 'sample', 'size', 'of', 'the', 'biased', 'sample', 'the', 'impact', 'of', 'sample', 'bias', 'can', 'likely', 'be', 'reduced', 'Hence', 'we', 'conclude', 'that', 'the', 'possible', 'impact', 'of', 'any', 'reduction', 'of', 'sample', 'bias', 'is', 'modest', 'in', 'a', 'consumer', 'credit', 'scoring', 'model', 'and', 'that', 'attention', 'might', 'optimally', 'be', 'focused', 'on', 'other', 'factors', 'leading', 'to', 'improved', 'consumer', 'credit', 'scoring', 'Keywords', 'Consumer', 'Credit', 'Scoring', 'Sample', 'Bias', 'Reject', 'Inference']\n",
      "\n",
      "number of total strings : 278\n"
     ]
    }
   ],
   "source": [
    "_text4b = []\n",
    "\n",
    "for text in _text4a:\n",
    "    if len(text) != 0:\n",
    "        _text4b.append(text)\n",
    "print(_text4b)\n",
    "print('')\n",
    "print( 'number of total strings :', len(_text4b) )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "720c0212",
   "metadata": {},
   "source": [
    "#### Step 5 : Lower case all strings"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "adabc4c2",
   "metadata": {},
   "source": [
    "Check & Learn : Lower case a string "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "id": "320c6947",
   "metadata": {},
   "outputs": [],
   "source": [
    "#'BANGLADESH'.lower()\n",
    "#'Bangladesh'.lower()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "id": "c1640f36",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['1', 'the', 'impact', 'of', 'sample', 'bias', 'on', 'consumer', 'credit', 'scoring', 'performance', 'and', 'profitability', 'abstract', 'this', 'article', 'seeks', 'to', 'gain', 'insight', 'into', 'the', 'influence', 'of', 'sample', 'bias', 'in', 'a', 'consumer', 'credit', 'scoring', 'model', 'considering', 'the', 'vital', 'implications', 'on', 'revenues', 'and', 'costs', 'concerned', 'with', 'the', 'issuing', 'and', 'repayment', 'of', 'commercial', 'credit', 'predictive', 'performance', 'of', 'the', 'model', 'is', 'crucial', 'and', 'sample', 'bias', 'has', 'been', 'suggested', 'to', 'pose', 'a', 'sizeable', 'threat', 'to', 'profitability', 'due', 'to', 'its', 'implications', 'on', 'either', 'population', 'drainage', 'or', 'biased', 'estimates', 'whereas', 'in', 'previous', 'research', 'different', 'techniques', 'of', 'reducing', 'sample', 'bias', 'have', 'been', 'proposed', 'and', 'deployed', 'the', 'debate', 'around', 'the', 'impact', 'of', 'sample', 'bias', 'itself', 'has', 'predominantly', 'been', 'held', 'on', 'a', 'theoretical', 'level', 'the', 'dataset', 'that', 'was', 'used', 'in', 'this', 'study', 'however', 'provides', 'the', 'opportunity', 'to', 'investigate', 'the', 'issue', 'in', 'an', 'empirical', 'setting', 'based', 'on', 'the', 'data', 'of', 'a', 'mail-order', 'company', 'offering', 'short', 'term', 'consumer', 'credit', 'to', 'their', 'consumers', 'we', 'show', 'that', 'given', 'a', 'certain', 'sample', 'size', 'sample', 'bias', 'has', 'a', 'significant', 'effect', 'on', 'consumer', 'credit-scoring', 'performance', 'and', 'profitability', 'its', 'effect', 'is', 'composed', 'of', 'the', 'inclusion', 'of', 'rejected', 'orders', 'in', 'the', 'scoring', 'model', 'and', 'the', 'inclusion', 'of', 'these', 'orders', 'into', 'the', 'variable-selection', 'process', 'the', 'impact', 'of', 'the', 'effect', 'of', 'sample', 'bias', 'on', 'consumer', 'credit', 'scoring', 'performance', 'and', 'profitability', 'is', 'limited', 'and', 'in', 'consumer', 'credit', 'scoring', 'by', 'merely', 'increasing', 'the', 'sample', 'size', 'of', 'the', 'biased', 'sample', 'the', 'impact', 'of', 'sample', 'bias', 'can', 'likely', 'be', 'reduced', 'hence', 'we', 'conclude', 'that', 'the', 'possible', 'impact', 'of', 'any', 'reduction', 'of', 'sample', 'bias', 'is', 'modest', 'in', 'a', 'consumer', 'credit', 'scoring', 'model', 'and', 'that', 'attention', 'might', 'optimally', 'be', 'focused', 'on', 'other', 'factors', 'leading', 'to', 'improved', 'consumer', 'credit', 'scoring', 'keywords', 'consumer', 'credit', 'scoring', 'sample', 'bias', 'reject', 'inference']\n",
      "\n",
      "number of total strings : 278\n"
     ]
    }
   ],
   "source": [
    "_text5 = []\n",
    "for text in _text4b:\n",
    "    _text5.append(str(text).lower())\n",
    "print(_text5)\n",
    "print('')\n",
    "print( 'number of total strings :', len(_text5) )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f4cf001a",
   "metadata": {},
   "source": [
    "#### Step 6 : There are some compound strings, such as, seperated by dash. Need  to fix those strings."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "854fccb2",
   "metadata": {},
   "source": [
    "Check & Learn : append() method of a list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "id": "24159b15",
   "metadata": {},
   "outputs": [],
   "source": [
    "# a = [1,2,3]\n",
    "# b = 99          # here b is a scalar\n",
    "# a.append(b)\n",
    "# print(a)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2385d19b",
   "metadata": {},
   "source": [
    "Check & Learn : extend() method of a list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "id": "3d077295",
   "metadata": {},
   "outputs": [],
   "source": [
    "# a = [1,2,3]\n",
    "# b = [99]        # here b is a single-element list\n",
    "# a.extend(b)\n",
    "# print(a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "id": "7ba5ffd1",
   "metadata": {},
   "outputs": [],
   "source": [
    "_text6 = []\n",
    "\n",
    "for elem in _text5:\n",
    "    e = elem.split('-')\n",
    "\n",
    "    if len(e) == 1:\n",
    "        _text6.append(e[0])\n",
    "    elif len(e) > 1:\n",
    "        _text6.extend(e)\n",
    "    else:\n",
    "        pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "id": "3e571bc4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['1', 'the', 'impact', 'of', 'sample', 'bias', 'on', 'consumer', 'credit', 'scoring', 'performance', 'and', 'profitability', 'abstract', 'this', 'article', 'seeks', 'to', 'gain', 'insight', 'into', 'the', 'influence', 'of', 'sample', 'bias', 'in', 'a', 'consumer', 'credit', 'scoring', 'model', 'considering', 'the', 'vital', 'implications', 'on', 'revenues', 'and', 'costs', 'concerned', 'with', 'the', 'issuing', 'and', 'repayment', 'of', 'commercial', 'credit', 'predictive', 'performance', 'of', 'the', 'model', 'is', 'crucial', 'and', 'sample', 'bias', 'has', 'been', 'suggested', 'to', 'pose', 'a', 'sizeable', 'threat', 'to', 'profitability', 'due', 'to', 'its', 'implications', 'on', 'either', 'population', 'drainage', 'or', 'biased', 'estimates', 'whereas', 'in', 'previous', 'research', 'different', 'techniques', 'of', 'reducing', 'sample', 'bias', 'have', 'been', 'proposed', 'and', 'deployed', 'the', 'debate', 'around', 'the', 'impact', 'of', 'sample', 'bias', 'itself', 'has', 'predominantly', 'been', 'held', 'on', 'a', 'theoretical', 'level', 'the', 'dataset', 'that', 'was', 'used', 'in', 'this', 'study', 'however', 'provides', 'the', 'opportunity', 'to', 'investigate', 'the', 'issue', 'in', 'an', 'empirical', 'setting', 'based', 'on', 'the', 'data', 'of', 'a', 'mail', 'order', 'company', 'offering', 'short', 'term', 'consumer', 'credit', 'to', 'their', 'consumers', 'we', 'show', 'that', 'given', 'a', 'certain', 'sample', 'size', 'sample', 'bias', 'has', 'a', 'significant', 'effect', 'on', 'consumer', 'credit', 'scoring', 'performance', 'and', 'profitability', 'its', 'effect', 'is', 'composed', 'of', 'the', 'inclusion', 'of', 'rejected', 'orders', 'in', 'the', 'scoring', 'model', 'and', 'the', 'inclusion', 'of', 'these', 'orders', 'into', 'the', 'variable', 'selection', 'process', 'the', 'impact', 'of', 'the', 'effect', 'of', 'sample', 'bias', 'on', 'consumer', 'credit', 'scoring', 'performance', 'and', 'profitability', 'is', 'limited', 'and', 'in', 'consumer', 'credit', 'scoring', 'by', 'merely', 'increasing', 'the', 'sample', 'size', 'of', 'the', 'biased', 'sample', 'the', 'impact', 'of', 'sample', 'bias', 'can', 'likely', 'be', 'reduced', 'hence', 'we', 'conclude', 'that', 'the', 'possible', 'impact', 'of', 'any', 'reduction', 'of', 'sample', 'bias', 'is', 'modest', 'in', 'a', 'consumer', 'credit', 'scoring', 'model', 'and', 'that', 'attention', 'might', 'optimally', 'be', 'focused', 'on', 'other', 'factors', 'leading', 'to', 'improved', 'consumer', 'credit', 'scoring', 'keywords', 'consumer', 'credit', 'scoring', 'sample', 'bias', 'reject', 'inference']\n",
      "\n",
      "number of total strings : 281\n"
     ]
    }
   ],
   "source": [
    "print(_text6)\n",
    "print('')\n",
    "print( 'number of total strings :', len(_text6) )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5c1e3f03",
   "metadata": {},
   "source": [
    "#### Step 7 : Remove stopwords"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c8112133",
   "metadata": {},
   "source": [
    "First import `nltk` package"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "id": "6e509814",
   "metadata": {},
   "outputs": [],
   "source": [
    "# pip3 install nltk\n",
    "import nltk\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "645713ec",
   "metadata": {},
   "source": [
    "Download `stopwords`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "id": "ce79023e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# use this only once\n",
    "# nltk.download('stopwords')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "04e1721f",
   "metadata": {},
   "source": [
    "Look at the list of english `stopwords`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "id": "c7d50cb9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['i',\n",
       " 'me',\n",
       " 'my',\n",
       " 'myself',\n",
       " 'we',\n",
       " 'our',\n",
       " 'ours',\n",
       " 'ourselves',\n",
       " 'you',\n",
       " \"you're\",\n",
       " \"you've\",\n",
       " \"you'll\",\n",
       " \"you'd\",\n",
       " 'your',\n",
       " 'yours',\n",
       " 'yourself',\n",
       " 'yourselves',\n",
       " 'he',\n",
       " 'him',\n",
       " 'his',\n",
       " 'himself',\n",
       " 'she',\n",
       " \"she's\",\n",
       " 'her',\n",
       " 'hers',\n",
       " 'herself',\n",
       " 'it',\n",
       " \"it's\",\n",
       " 'its',\n",
       " 'itself',\n",
       " 'they',\n",
       " 'them',\n",
       " 'their',\n",
       " 'theirs',\n",
       " 'themselves',\n",
       " 'what',\n",
       " 'which',\n",
       " 'who',\n",
       " 'whom',\n",
       " 'this',\n",
       " 'that',\n",
       " \"that'll\",\n",
       " 'these',\n",
       " 'those',\n",
       " 'am',\n",
       " 'is',\n",
       " 'are',\n",
       " 'was',\n",
       " 'were',\n",
       " 'be',\n",
       " 'been',\n",
       " 'being',\n",
       " 'have',\n",
       " 'has',\n",
       " 'had',\n",
       " 'having',\n",
       " 'do',\n",
       " 'does',\n",
       " 'did',\n",
       " 'doing',\n",
       " 'a',\n",
       " 'an',\n",
       " 'the',\n",
       " 'and',\n",
       " 'but',\n",
       " 'if',\n",
       " 'or',\n",
       " 'because',\n",
       " 'as',\n",
       " 'until',\n",
       " 'while',\n",
       " 'of',\n",
       " 'at',\n",
       " 'by',\n",
       " 'for',\n",
       " 'with',\n",
       " 'about',\n",
       " 'against',\n",
       " 'between',\n",
       " 'into',\n",
       " 'through',\n",
       " 'during',\n",
       " 'before',\n",
       " 'after',\n",
       " 'above',\n",
       " 'below',\n",
       " 'to',\n",
       " 'from',\n",
       " 'up',\n",
       " 'down',\n",
       " 'in',\n",
       " 'out',\n",
       " 'on',\n",
       " 'off',\n",
       " 'over',\n",
       " 'under',\n",
       " 'again',\n",
       " 'further',\n",
       " 'then',\n",
       " 'once',\n",
       " 'here',\n",
       " 'there',\n",
       " 'when',\n",
       " 'where',\n",
       " 'why',\n",
       " 'how',\n",
       " 'all',\n",
       " 'any',\n",
       " 'both',\n",
       " 'each',\n",
       " 'few',\n",
       " 'more',\n",
       " 'most',\n",
       " 'other',\n",
       " 'some',\n",
       " 'such',\n",
       " 'no',\n",
       " 'nor',\n",
       " 'not',\n",
       " 'only',\n",
       " 'own',\n",
       " 'same',\n",
       " 'so',\n",
       " 'than',\n",
       " 'too',\n",
       " 'very',\n",
       " 's',\n",
       " 't',\n",
       " 'can',\n",
       " 'will',\n",
       " 'just',\n",
       " 'don',\n",
       " \"don't\",\n",
       " 'should',\n",
       " \"should've\",\n",
       " 'now',\n",
       " 'd',\n",
       " 'll',\n",
       " 'm',\n",
       " 'o',\n",
       " 're',\n",
       " 've',\n",
       " 'y',\n",
       " 'ain',\n",
       " 'aren',\n",
       " \"aren't\",\n",
       " 'couldn',\n",
       " \"couldn't\",\n",
       " 'didn',\n",
       " \"didn't\",\n",
       " 'doesn',\n",
       " \"doesn't\",\n",
       " 'hadn',\n",
       " \"hadn't\",\n",
       " 'hasn',\n",
       " \"hasn't\",\n",
       " 'haven',\n",
       " \"haven't\",\n",
       " 'isn',\n",
       " \"isn't\",\n",
       " 'ma',\n",
       " 'mightn',\n",
       " \"mightn't\",\n",
       " 'mustn',\n",
       " \"mustn't\",\n",
       " 'needn',\n",
       " \"needn't\",\n",
       " 'shan',\n",
       " \"shan't\",\n",
       " 'shouldn',\n",
       " \"shouldn't\",\n",
       " 'wasn',\n",
       " \"wasn't\",\n",
       " 'weren',\n",
       " \"weren't\",\n",
       " 'won',\n",
       " \"won't\",\n",
       " 'wouldn',\n",
       " \"wouldn't\"]"
      ]
     },
     "execution_count": 170,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nltk.corpus.stopwords.words('english')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6a839abd",
   "metadata": {},
   "source": [
    "How can you find Bangla stopwords?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "id": "cbfda387",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['অতএব', 'অথচ', 'অথবা', 'অনুযায়ী', 'অনেক', 'অনেকে', 'অনেকেই', 'অন্তত', 'অন্য', 'অবধি', 'অবশ্য', 'অর্থাত', 'আই', 'আগামী', 'আগে', 'আগেই', 'আছে', 'আজ', 'আদ্যভাগে', 'আপনার', 'আপনি', 'আবার', 'আমরা', 'আমাকে', 'আমাদের', 'আমার', 'আমি', 'আর', 'আরও', 'ই', 'ইত্যাদি', 'ইহা', 'উচিত', 'উত্তর', 'উনি', 'উপর', 'উপরে', 'এ', 'এঁদের', 'এঁরা', 'এই', 'একই', 'একটি', 'একবার', 'একে', 'এক্', 'এখন', 'এখনও', 'এখানে', 'এখানেই', 'এটা', 'এটাই', 'এটি', 'এত', 'এতটাই', 'এতে', 'এদের', 'এব', 'এবং', 'এবার', 'এমন', 'এমনকী', 'এমনি', 'এর', 'এরা', 'এল', 'এস', 'এসে', 'ঐ', 'ও', 'ওঁদের', 'ওঁর', 'ওঁরা', 'ওই', 'ওকে', 'ওখানে', 'ওদের', 'ওর', 'ওরা', 'কখনও', 'কত', 'কবে', 'কমনে', 'কয়েক', 'কয়েকটি', 'করছে', 'করছেন', 'করতে', 'করবে', 'করবেন', 'করলে', 'করলেন', 'করা', 'করাই', 'করায়', 'করার', 'করি', 'করিতে', 'করিয়া', 'করিয়ে', 'করে', 'করেই', 'করেছিলেন', 'করেছে', 'করেছেন', 'করেন', 'কাউকে', 'কাছ', 'কাছে', 'কাজ', 'কাজে', 'কারও', 'কারণ', 'কি', 'কিংবা', 'কিছু', 'কিছুই', 'কিন্তু', 'কী', 'কে', 'কেউ', 'কেউই', 'কেখা', 'কেন', 'কোটি', 'কোন', 'কোনও', 'কোনো', 'ক্ষেত্রে', 'কয়েক', 'খুব', 'গিয়ে', 'গিয়েছে', 'গিয়ে', 'গুলি', 'গেছে', 'গেল', 'গেলে', 'গোটা', 'চলে', 'চান', 'চায়', 'চার', 'চালু', 'চেয়ে', 'চেষ্টা', 'ছাড়া', 'ছাড়াও', 'ছিল', 'ছিলেন', 'জন', 'জনকে', 'জনের', 'জন্য', 'জন্যওজে', 'জানতে', 'জানা', 'জানানো', 'জানায়', 'জানিয়ে', 'জানিয়েছে', 'জে', 'জ্নজন', 'টি', 'ঠিক', 'তখন', 'তত', 'তথা', 'তবু', 'তবে', 'তা', 'তাঁকে', 'তাঁদের', 'তাঁর', 'তাঁরা', 'তাঁাহারা', 'তাই', 'তাও', 'তাকে', 'তাতে', 'তাদের', 'তার', 'তারপর', 'তারা', 'তারৈ', 'তাহলে', 'তাহা', 'তাহাতে', 'তাহার', 'তিনঐ', 'তিনি', 'তিনিও', 'তুমি', 'তুলে', 'তেমন', 'তো', 'তোমার', 'থাকবে', 'থাকবেন', 'থাকা', 'থাকায়', 'থাকে', 'থাকেন', 'থেকে', 'থেকেই', 'থেকেও', 'দিকে', 'দিতে', 'দিন', 'দিয়ে', 'দিয়েছে', 'দিয়েছেন', 'দিলেন', 'দু', 'দুই', 'দুটি', 'দুটো', 'দেওয়া', 'দেওয়ার', 'দেওয়া', 'দেখতে', 'দেখা', 'দেখে', 'দেন', 'দেয়', 'দ্বারা', 'ধরা', 'ধরে', 'ধামার', 'নতুন', 'নয়', 'না', 'নাই', 'নাকি', 'নাগাদ', 'নানা', 'নিজে', 'নিজেই', 'নিজেদের', 'নিজের', 'নিতে', 'নিয়ে', 'নিয়ে', 'নেই', 'নেওয়া', 'নেওয়ার', 'নেওয়া', 'নয়', 'পক্ষে', 'পর', 'পরে', 'পরেই', 'পরেও', 'পর্যন্ত', 'পাওয়া', 'পাচ', 'পারি', 'পারে', 'পারেন', 'পি', 'পেয়ে', 'পেয়্র্', 'প্রতি', 'প্রথম', 'প্রভৃতি', 'প্রযন্ত', 'প্রাথমিক', 'প্রায়', 'প্রায়', 'ফলে', 'ফিরে', 'ফের', 'বক্তব্য', 'বদলে', 'বন', 'বরং', 'বলতে', 'বলল', 'বললেন', 'বলা', 'বলে', 'বলেছেন', 'বলেন', 'বসে', 'বহু', 'বা', 'বাদে', 'বার', 'বি', 'বিনা', 'বিভিন্ন', 'বিশেষ', 'বিষয়টি', 'বেশ', 'বেশি', 'ব্যবহার', 'ব্যাপারে', 'ভাবে', 'ভাবেই', 'মতো', 'মতোই', 'মধ্যভাগে', 'মধ্যে', 'মধ্যেই', 'মধ্যেও', 'মনে', 'মাত্র', 'মাধ্যমে', 'মোট', 'মোটেই', 'যখন', 'যত', 'যতটা', 'যথেষ্ট', 'যদি', 'যদিও', 'যা', 'যাঁর', 'যাঁরা', 'যাওয়া', 'যাওয়ার', 'যাওয়া', 'যাকে', 'যাচ্ছে', 'যাতে', 'যাদের', 'যান', 'যাবে', 'যায়', 'যার', 'যারা', 'যিনি', 'যে', 'যেখানে', 'যেতে', 'যেন', 'যেমন', 'র', 'রকম', 'রয়েছে', 'রাখা', 'রেখে', 'লক্ষ', 'শুধু', 'শুরু', 'সঙ্গে', 'সঙ্গেও', 'সব', 'সবার', 'সমস্ত', 'সম্প্রতি', 'সহ', 'সহিত', 'সাধারণ', 'সামনে', 'সি', 'সুতরাং', 'সে', 'সেই', 'সেখান', 'সেখানে', 'সেটা', 'সেটাই', 'সেটাও', 'সেটি', 'স্পষ্ট', 'স্বয়ং', 'হইতে', 'হইবে', 'হইয়া', 'হওয়া', 'হওয়ায়', 'হওয়ার', 'হচ্ছে', 'হত', 'হতে', 'হতেই', 'হন', 'হবে', 'হবেন', 'হয়', 'হয়তো', 'হয়নি', 'হয়ে', 'হয়েই', 'হয়েছিল', 'হয়েছে', 'হয়েছেন', 'হল', 'হলে', 'হলেই', 'হলেও', 'হলো', 'হাজার', 'হিসাবে', 'হৈলে', 'হোক', 'হয়']\n"
     ]
    }
   ],
   "source": [
    "print(nltk.corpus.stopwords.words('bengali'))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a72605b9",
   "metadata": {},
   "source": [
    "Remove english stopwords from the list `_text6`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "id": "239fb879",
   "metadata": {},
   "outputs": [],
   "source": [
    "# _text7 = [ w for w in _text6 if not w.lower() in stopwords.words('english')]\n",
    "stopwords = nltk.corpus.stopwords.words('english')\n",
    "_text7 = []\n",
    "\n",
    "for w in _text6:\n",
    "    if not w.lower() in stopwords:\n",
    "        _text7.append(w)\n",
    "\n",
    "\n",
    "# write your code here"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "id": "4d1051ed",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['1', 'impact', 'sample', 'bias', 'consumer', 'credit', 'scoring', 'performance', 'profitability', 'abstract', 'article', 'seeks', 'gain', 'insight', 'influence', 'sample', 'bias', 'consumer', 'credit', 'scoring', 'model', 'considering', 'vital', 'implications', 'revenues', 'costs', 'concerned', 'issuing', 'repayment', 'commercial', 'credit', 'predictive', 'performance', 'model', 'crucial', 'sample', 'bias', 'suggested', 'pose', 'sizeable', 'threat', 'profitability', 'due', 'implications', 'either', 'population', 'drainage', 'biased', 'estimates', 'whereas', 'previous', 'research', 'different', 'techniques', 'reducing', 'sample', 'bias', 'proposed', 'deployed', 'debate', 'around', 'impact', 'sample', 'bias', 'predominantly', 'held', 'theoretical', 'level', 'dataset', 'used', 'study', 'however', 'provides', 'opportunity', 'investigate', 'issue', 'empirical', 'setting', 'based', 'data', 'mail', 'order', 'company', 'offering', 'short', 'term', 'consumer', 'credit', 'consumers', 'show', 'given', 'certain', 'sample', 'size', 'sample', 'bias', 'significant', 'effect', 'consumer', 'credit', 'scoring', 'performance', 'profitability', 'effect', 'composed', 'inclusion', 'rejected', 'orders', 'scoring', 'model', 'inclusion', 'orders', 'variable', 'selection', 'process', 'impact', 'effect', 'sample', 'bias', 'consumer', 'credit', 'scoring', 'performance', 'profitability', 'limited', 'consumer', 'credit', 'scoring', 'merely', 'increasing', 'sample', 'size', 'biased', 'sample', 'impact', 'sample', 'bias', 'likely', 'reduced', 'hence', 'conclude', 'possible', 'impact', 'reduction', 'sample', 'bias', 'modest', 'consumer', 'credit', 'scoring', 'model', 'attention', 'might', 'optimally', 'focused', 'factors', 'leading', 'improved', 'consumer', 'credit', 'scoring', 'keywords', 'consumer', 'credit', 'scoring', 'sample', 'bias', 'reject', 'inference']\n",
      "\n",
      "number of total strings : 169\n"
     ]
    }
   ],
   "source": [
    "print( _text7 )\n",
    "print('')\n",
    "print( 'number of total strings :', len(_text7) )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b6f8498f",
   "metadata": {},
   "source": [
    "#### Step 8 : Stemming words   \n",
    "\n",
    "`!!!! Use this step with caution !!!!`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "id": "3ece6bc4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# from nltk.stem.snowball import EnglishStemmer\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "# nltk.download('wordnet')\n",
    "# nltk.download('omw-1.4')\n",
    "from nltk.stem import PorterStemmer\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "82a17011",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "id": "9e74cc8e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.stem.snowball import EnglishStemmer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "id": "8bd0313b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['1', 'impact', 'sampl', 'bias', 'consum', 'credit', 'score', 'perform', 'profit', 'abstract', 'articl', 'seek', 'gain', 'insight', 'influenc', 'sampl', 'bias', 'consum', 'credit', 'score', 'model', 'consid', 'vital', 'implic', 'revenu', 'cost', 'concern', 'issu', 'repay', 'commerci', 'credit', 'predict', 'perform', 'model', 'crucial', 'sampl', 'bias', 'suggest', 'pose', 'sizeabl', 'threat', 'profit', 'due', 'implic', 'either', 'popul', 'drainag', 'bias', 'estim', 'wherea', 'previous', 'research', 'differ', 'techniqu', 'reduc', 'sampl', 'bias', 'propos', 'deploy', 'debat', 'around', 'impact', 'sampl', 'bias', 'predomin', 'held', 'theoret', 'level', 'dataset', 'use', 'studi', 'howev', 'provid', 'opportun', 'investig', 'issu', 'empir', 'set', 'base', 'data', 'mail', 'order', 'compani', 'offer', 'short', 'term', 'consum', 'credit', 'consum', 'show', 'given', 'certain', 'sampl', 'size', 'sampl', 'bias', 'signific', 'effect', 'consum', 'credit', 'score', 'perform', 'profit', 'effect', 'compos', 'inclus', 'reject', 'order', 'score', 'model', 'inclus', 'order', 'variabl', 'select', 'process', 'impact', 'effect', 'sampl', 'bias', 'consum', 'credit', 'score', 'perform', 'profit', 'limit', 'consum', 'credit', 'score', 'mere', 'increas', 'sampl', 'size', 'bias', 'sampl', 'impact', 'sampl', 'bias', 'like', 'reduc', 'henc', 'conclud', 'possibl', 'impact', 'reduct', 'sampl', 'bias', 'modest', 'consum', 'credit', 'score', 'model', 'attent', 'might', 'optim', 'focus', 'factor', 'lead', 'improv', 'consum', 'credit', 'score', 'keyword', 'consum', 'credit', 'score', 'sampl', 'bias', 'reject', 'infer']\n",
      "\n",
      "number of total strings : 169\n"
     ]
    }
   ],
   "source": [
    "stemmer = EnglishStemmer()\n",
    "\n",
    "_text8 = []\n",
    "\n",
    "for word in _text7:\n",
    "    _text8.append(stemmer.stem(word))\n",
    "\n",
    "print( _text8 )\n",
    "print('')\n",
    "print( 'number of total strings :', len(_text8) )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "82460a28",
   "metadata": {},
   "source": [
    "## Part 3 : Porcess Data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6b482995",
   "metadata": {},
   "source": [
    "#### Step 1 : Save each page as a `key-value` pair in  a dictionary "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 177,
   "id": "bfa284c1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['1', 'impact', 'sampl', 'bias', 'consum', 'credit', 'score', 'perform', 'profit', 'abstract', 'articl', 'seek', 'gain', 'insight', 'influenc', 'sampl', 'bias', 'consum', 'credit', 'score', 'model', 'consid', 'vital', 'implic', 'revenu', 'cost', 'concern', 'issu', 'repay', 'commerci', 'credit', 'predict', 'perform', 'model', 'crucial', 'sampl', 'bias', 'suggest', 'pose', 'sizeabl', 'threat', 'profit', 'due', 'implic', 'either', 'popul', 'drainag', 'bias', 'estim', 'wherea', 'previous', 'research', 'differ', 'techniqu', 'reduc', 'sampl', 'bias', 'propos', 'deploy', 'debat', 'around', 'impact', 'sampl', 'bias', 'predomin', 'held', 'theoret', 'level', 'dataset', 'use', 'studi', 'howev', 'provid', 'opportun', 'investig', 'issu', 'empir', 'set', 'base', 'data', 'mail', 'order', 'compani', 'offer', 'short', 'term', 'consum', 'credit', 'consum', 'show', 'given', 'certain', 'sampl', 'size', 'sampl', 'bias', 'signific', 'effect', 'consum', 'credit', 'score', 'perform', 'profit', 'effect', 'compos', 'inclus', 'reject', 'order', 'score', 'model', 'inclus', 'order', 'variabl', 'select', 'process', 'impact', 'effect', 'sampl', 'bias', 'consum', 'credit', 'score', 'perform', 'profit', 'limit', 'consum', 'credit', 'score', 'mere', 'increas', 'sampl', 'size', 'bias', 'sampl', 'impact', 'sampl', 'bias', 'like', 'reduc', 'henc', 'conclud', 'possibl', 'impact', 'reduct', 'sampl', 'bias', 'modest', 'consum', 'credit', 'score', 'model', 'attent', 'might', 'optim', 'focus', 'factor', 'lead', 'improv', 'consum', 'credit', 'score', 'keyword', 'consum', 'credit', 'score', 'sampl', 'bias', 'reject', 'infer']\n",
      "\n",
      "['2', '1', 'introduct', 'paper', 'term', 'credit', 'score', 'use', 'common', 'denomin', 'statist', 'method', 'use', 'classifi', 'applic', 'credit', 'good', 'bad', 'risk', 'class', 'use', 'various', 'predict', 'variabl', 'applic', 'form', 'extern', 'data', 'supplier', 'compani', 'record', 'statist', 'model', 'industri', 'often', 'term', 'scorecard', 'use', 'yield', 'estim', 'probabl', 'default', 'typic', 'accept', 'reject', 'decis', 'taken', 'compar', 'estim', 'probabl', 'default', 'suitabl', 'threshold', '(see', 'eg', 'hand', 'henley', '1997)', 'sinc', 'begin', 'credit', 'score', 'techniqu', 'issu', 'sampl', 'bias', 'rapid', 'grown', 'becom', 'intrigu', 'topic', 'credit', 'score', 'domain', '(see', 'eg', 'chandler', 'coffman', '1977)', 'challeng', 'lie', 'estim', 'default', 'probabl', 'futur', 'credit', 'applic', 'use', 'model', 'train', 'skew', 'sampl', 'previous', 'accept', 'applic', 'inde', 'histor', 'reject', 'applic', 'unabl', 'observ', 'outcom', 'whether', 'applic', 'abl', 'refund', 'debt', 'reject', 'infer', '(see', 'eg', 'hand', 'henley', '1994)', 'compris', 'set', 'procedur', 'determin', 'decreas', 'bias', 'aris', 'build', 'score', 'model', 'accept', 'applic', 'eg', 'imput', 'target', 'variabl', 'reject', 'case', 'exist', 'literatur', 'domain', 'main', 'focus', 'describ', '(to', 'lesser', 'extent)', 'test', 'differ', 'procedur', 'reject', 'infer', 'paper', 'due', 'special', 'featur', 'data', 'set', 'use', 'focus', 'result', 'could', 'reach', 'perfect', 'reject', 'infer', 'would', 'occur', 'way', 'hope', 'shed', 'new', 'light', 'upon', 'relev', 'reject', 'infer', 'procedur', 'consum', 'credit', 'score', 'set', 'remaind', 'paper', 'structur', 'follow', 'section', '2', 'discuss', 'issu', 'sampl', 'bias', 'reject', 'infer', 'credit', 'score', 'literatur', 'section', '3', 'cover', 'methodolog', 'use', 'empir', 'part', 'paper', 'research', 'impact', 'sampl', 'bias', 'credit', 'score', 'perform', 'profit', 'section', '4', 'handl', 'data', 'descript', 'data', 'set', 'use', 'sampl', 'composit', 'need', 'empir', 'studi', 'section', '5', 'report', 'find', 'differ', 'research', 'questi', 'on', 'defin', 'throughout', 'paper', 'final', 'conclus', 'limit', 'issu', 'research', 'given', 'section', '6', '7', 'respect']\n",
      "\n",
      "['32', 'sampl', 'bias', 'credit', 'score', 'literatur', 'consid', 'widespread', 'use', 'statist', 'score', 'techniqu', 'consum', 'credit', 'industri', 'consid', 'longev', 'consum', 'credit', 'score', 'research', '(see', 'eg', 'myer', 'forgi', '1963', 'earli', 'application1)', 'literatur', 'surround', 'custom', 'credit', 'score', 'grow', 'steadili', '(for', 'overview', 'see', 'eg', 'thoma', '2000)', 'studi', 'focus', 'applic', 'score', '(see', 'eg', 'hand', '2001', 'overview)', 'ie', 'consid', 'decis', 'whether', 'grant', 'credit', 'potenti', 'lender', 'upon', 'applic', 'contrast', 'recent', 'introduc', 'behavior', 'score', '(see', 'eg', 'thoma', 'et', 'al', '2001)', 'perform', 'custom', 'assess', 'decis', 'make', 'purpos', 'lifetim', 'relev', 'credit', '(eg', 'whether', 'credit', 'limit', 'current', 'borrow', 'increased)', 'henc', 'focus', 'core', 'applic', 'within', 'domain', 'import', 'fascin', 'topic', 'provid', 'much', 'debat', 'credit', 'score', 'concern', 'issu', 'sampl', 'bias', 'new', 'credit', 'score', 'model', 'built', 'previous', 'compani', 'record', 'previous', 'accept', 'order', 'use', 'build', 'new', 'credit', 'score', 'henc', 'sampl', 'bias', 'aris', 'sampl', 'order', 'use', 'model', 'build', 'repres', 'through', 'door', 'applic', 'popul', '(chandler', 'coffman', '1977)', 'inde', 'mention', 'hand', 'henley', '(1994)', 'reject', 'region', 'design', 'precis', 'differ', 'non', 'trivial', 'way', 'accept', 'region', 'histor', 'sampl', 'bias', 'accus', 'introduc', 'least', 'one', 'two', 'major', 'shortcom', 'model', 'name', 'popul', 'drainag', 'bias', 'estim', 'technic', 'new', 'score', 'appli', 'custom', 'accept', 'past', '(see', 'eg', 'joan', '1994)', 'reject', 'remain', 'reject', 'lead', 'inevit', 'decreas', 'custom', 'base', 'lack', 'appropri', 'term', 'credit', 'score', 'paper', 'use', 'term', 'popul', 'drainag', 'cover', 'phenomenon', 'altern', 'score', 'appli', 'futur', 'order', 'bias', 'estim', 'would', 'result', 'credit', 'applic', 'would', 'reject', 'previous', 'credit', 'score', '(see', 'eg', 'hand', 'henley', '1994)', 'understand', 'consequ', 'propos', 'negat', 'influenc', 'compani', 'profit', 'consid', 'first', 'intrigu', 'problem', 'hand', 'second', 'initi', 'report', 'sizeabl', 'influenc', 'sampl', 'bias', 'use', 'discrimin', 'analysi', '(averi', '1981)', 'previous', 'research', 'histor', 'focus', 'imput', 'techniqu', 'wherebi', 'one', 'attempt', 'predict', '1', 'studi', 'previous', 'studi', 'deal', 'develop', 'numer', 'rate', 'system', 'cite', 'date', 'back', '1940s']\n",
      "\n",
      "['4the', 'outcom', 'previous', 'reject', 'order', 'henceforth', 'call', 'reject', 'infer', 'fact', 'research', 'possibl', 'method', 'reject', 'infer', 'date', 'back', 'almost', 'far', 'begin', 'credit', 'score', '(see', 'eg', 'hsia', '1978)', 'overview', 'method', 'wide', 'ly', 'avail', '(see', 'eg', 'joan', '1994', 'hand', 'henley', '1997)', 'might', 'use', 'cover', 'briefli', 'idea', 'behind', 'two', 'renown', 'reject', 'infer', 'techniqu', 'includ', 'augment', 'accept', 'order', 'weigh', 'invers', 'proport', 'probabl', 'order', 'accept', 'order', 'increas', 'impact', 'der', 'compar', 'order', 'reject', 'iter', 'reclassif', 'reject', 'order', 'score', 'discret', 'use', 'classif', 'rule', 'deriv', 'accept', 'order', 'model', 'estim', 'divid', 'data', 'sampl', 'size', 'origin', 'accept', 'reject', 'region', 'procedur', 'iter', 'repeat', 'converg', 'occur', '(see', 'eg', 'joan', '1994)', 'result', 'various', 'attempt', 'reject', 'infer', 'howev', 'seem', 'riski', 'best', 'lead', 'author', 'conclud', 'reliabl', 'reject', 'infer', 'imposs', '(hand', 'henley', '1994)', 'contrast', 'studi', 'reject', 'infer', 'possibl', 'impact', 'sampl', 'bias', 'custom', 'credit', 'score', 'cover', 'much', 'lesser', 'extent', 'addit', 'argu', 'recent', 'use', 'discrimin', 'analysi', 'introduc', 'bias', 'wherebi', 'previous', 'find', 'concern', 'impact', 'sampl', 'bias', '(in', 'eg', 'averi', '1981)', 'reconsid', 'shortag', 'random', 'sampl', 'reject', 'order', 'mention', 'frequent', 'cost', 'involv', 'gain', 'data', 'often', 'mention', 'breath', '(see', 'eg', 'hand', 'henley', '1994', '1997)', 'due', 'fact', 'data', 'set', 'use', 'studi', 'contain', 'real', 'outcom', 'valu', 'sizeabl', 'group', 'order', 'reject', 'statist', 'score', 'process', 'abl', 'assess', 'import', 'sampl', 'bias', 'upper', 'limit', 'benefit', 'could', 'result', 'use', 'model', 'reject', 'infer', 'henc', 'lie', 'within', 'ambit', 'studi', 'test', 'perform', 'propos', 'reject', 'infer', 'method', 'given', 'fact', 'reject', 'infer', 'deal', 'attempt', 'infer', 'true', 'creditworthi', 'status', 'reject', 'applic', '(hand', 'henley', '1994)', 'would', 'seem', 'benefici', 'estim', 'maxim', 'improv', 'could', 'reach', 'imput', 'method', '100', '%', 'correct']\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import PyPDF2\n",
    "import re\n",
    "import nltk\n",
    "\n",
    "import json\n",
    "\n",
    "from nltk.stem.snowball import EnglishStemmer\n",
    "# nltk.download('wordnet')\n",
    "# nltk.download('omw-1.4')\n",
    "from nltk.stem import PorterStemmer # stemmer lib\n",
    "\n",
    "reader = PyPDF2.PdfFileReader(open('example.pdf','rb')) # pdf file\n",
    "\n",
    "\n",
    "def analyse(page_number): # function\n",
    "    page = reader.pages[page_number] # current page\n",
    "#     print(page)\n",
    "    text = page.extract_text() # extract text\n",
    "#     print(text)\n",
    "    _text1 = text.split(\" \") # split string\n",
    "#     print( _text1)\n",
    "\n",
    "    _text2a = []\n",
    "    for text in _text1:\n",
    "        _text2a.append(str(text).replace('\\n','').strip()) # replace and strip\n",
    "#     print(_text2a)\n",
    "    _text2b = []\n",
    "\n",
    "    for text in _text2a:\n",
    "        if len(text) != 0:\n",
    "            _text2b.append(text) # storing text\n",
    "#     print(_text2b)\n",
    "    \n",
    "    _text3 = []\n",
    "\n",
    "    for text in _text2b:\n",
    "        _text3.append(re.sub('[:,;.\\[\\]]', '', text)) # storing text\n",
    "\n",
    "#     print(_text3)\n",
    "#     print('')\n",
    "#     print( 'number of total strings :', len(_text3) )\n",
    "    \n",
    "    _text4a = []\n",
    "\n",
    "    for text in _text3:\n",
    "        _text4a.append(re.sub('\\([a-z]+\\)','',text)) # storing text\n",
    "\n",
    "#     print(_text4a)\n",
    "#     print('')\n",
    "#     print( 'number of total strings :', len(_text4a) )\n",
    "    \n",
    "    _text4b = []\n",
    "\n",
    "    for text in _text4a:\n",
    "        if len(text) != 0:\n",
    "            _text4b.append(text) # storing text\n",
    "#     print(_text4b)\n",
    "#     print('')\n",
    "#     print( 'number of total strings :', len(_text4b) )\n",
    "    \n",
    "    _text5 = []\n",
    "    for text in _text4b:\n",
    "        _text5.append(str(text).lower()) # storing text\n",
    "#     print(_text5)\n",
    "#     print('')\n",
    "#     print( 'number of total strings :', len(_text5) )\n",
    "    \n",
    "    _text6 = []\n",
    "\n",
    "    for elem in _text5:\n",
    "        e = elem.split('-')\n",
    "\n",
    "        if len(e) == 1:\n",
    "            _text6.append(e[0]) # storing text\n",
    "        elif len(e) > 1:\n",
    "            _text6.extend(e) # extend list\n",
    "        else:\n",
    "            pass\n",
    "#     print(_text6)\n",
    "#     print('')\n",
    "#     print( 'number of total strings :', len(_text6) )\n",
    "    \n",
    "    \n",
    "    stopwords = nltk.corpus.stopwords.words('english') # stopwords\n",
    "    \n",
    "    _text7 = [ word for word in _text6 if not word.lower() in stopwords]\n",
    "#     print( _text7 )\n",
    "#     print('')\n",
    "#     print( 'number of total strings :', len(_text7) )\n",
    "    \n",
    "    stemmer = EnglishStemmer()\n",
    "\n",
    "    _text8 = []\n",
    "\n",
    "    for word in _text7:\n",
    "        _text8.append(stemmer.stem(word))\n",
    "\n",
    "#     print( _text8 )\n",
    "#     print('')\n",
    "#     print( 'number of total strings :', len(_text8) )\n",
    "    \n",
    "    return _text8 # return final text\n",
    "\n",
    " \n",
    "\n",
    "#####################################################################\n",
    "# export data\n",
    "\n",
    "number_of_pages = reader.getNumPages() # total page\n",
    "data = [] # data\n",
    "    \n",
    "## for each page:\n",
    "for i in range(0, number_of_pages):\n",
    "    data.append(analyse(i))\n",
    "#     print(\"-----------------------------\",i+1,\"--------------\")\n",
    "\n",
    "# data\n",
    "\n",
    "## store data in dictionary\n",
    "dict = {}\n",
    "for i in range(len(data)):\n",
    "    for word in data:\n",
    "        dict[f'Page {i+1}'] = data[i]\n",
    "\n",
    "        \n",
    "for keys in dict.keys():\n",
    "    print(dict[keys])\n",
    "    print()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
